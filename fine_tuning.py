import os
import tensorflow as tf

# ==============================
# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
# ==============================
IMAGE_SIZE = (64, 64)
BATCH_SIZE = 32
EPOCHS = 5
LEARNING_RATE = 1e-5

BASE_MODEL_PATH = "models/asl_words_model.keras"
FINETUNE_DATA_DIR = "asl_finetune_data"
SAVE_PATH = "models/asl_model_finetuned.keras"

# ==============================
# å­¦ç¿’å¯¾è±¡ã‚¯ãƒ©ã‚¹ã‚’æŒ‡å®šï¼ˆä¾‹: A, B, nothing ã®ã¿ï¼‰
# ==============================
TARGET_CLASSES = ["A", "B", "C", "nothing"]

# ==============================
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿
# ==============================
if not os.path.exists(FINETUNE_DATA_DIR):
    raise FileNotFoundError(f"è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {FINETUNE_DATA_DIR}")

train_ds = tf.keras.utils.image_dataset_from_directory(
    FINETUNE_DATA_DIR,
    image_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    labels="inferred",
    label_mode="int",
    class_names=TARGET_CLASSES   # âœ… å­¦ç¿’ã•ã›ãŸã„ã‚¯ãƒ©ã‚¹ã ã‘æŒ‡å®š
)

# æ­£è¦åŒ–
normalization_layer = tf.keras.layers.Rescaling(1./255)
train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)

# ==============================
# ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
# ==============================
if not os.path.exists(BASE_MODEL_PATH):
    raise FileNotFoundError(f"ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {BASE_MODEL_PATH}")

base_model = tf.keras.models.load_model(BASE_MODEL_PATH)

# ==============================
# Sequential ãƒ¢ãƒ‡ãƒ«å¯¾å¿œã®å‡ºåŠ›å±¤å·®ã—æ›¿ãˆ
# ==============================
if isinstance(base_model, tf.keras.Sequential):
    # æœ€å¾Œã®å±¤ã‚’å‰Šé™¤
    base_model.pop()
    # æ–°ã—ã„å‡ºåŠ›å±¤ã‚’è¿½åŠ ï¼ˆåå‰ã‚’ãƒ¦ãƒ‹ãƒ¼ã‚¯ã«ã™ã‚‹ï¼‰
    base_model.add(tf.keras.layers.Dense(len(TARGET_CLASSES), activation="softmax", name="custom_output"))
    model = base_model
else:
    # Functional ãƒ¢ãƒ‡ãƒ«ãªã‚‰ Functional API ã§å†æ§‹ç¯‰
    inputs = tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))
    x = base_model(inputs, training=False)
    outputs = tf.keras.layers.Dense(len(TARGET_CLASSES), activation="softmax", name="custom_output")(x)
    model = tf.keras.Model(inputs, outputs)

# ==============================
# Convå±¤ã‚’å‡çµï¼ˆæœ€å¾Œã® Dense ä»¥å¤–ï¼‰
# ==============================
for layer in model.layers[:-1]:
    layer.trainable = False

# ==============================
# ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
# ==============================
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

# ==============================
# ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
# ==============================
print("ğŸ”„ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹...")
history = model.fit(train_ds, epochs=EPOCHS)

# ==============================
# ä¿å­˜
# ==============================
model.save(SAVE_PATH)
print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {SAVE_PATH}")
