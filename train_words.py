import tensorflow as tf
import numpy as np
import os

# ==============================
# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
# ==============================
IMAGE_SIZE = (64, 64)
BATCH_SIZE = 32
EPOCHS = 10
DATA_DIR = "asl_words_train"   # â† ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
SAVE_DIR = "models"
EXTENTION = "keras"
os.makedirs(SAVE_DIR, exist_ok=True)
SAVE_PATH = os.path.join(SAVE_DIR, f"asl_words_model.{EXTENTION}")
print(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆ: {SAVE_PATH}")

# ==============================
# ã‚¯ãƒ©ã‚¹åãƒªã‚¹ãƒˆ
# ==============================
classes = [
    "I_Love_You",
    "Yes",
    "No",
    "Hello",
    "Thank_You",
    "Good",
    "Sorry",
    "Please",
    "Nothing"  # ğŸ‘ˆ è¿½åŠ ï¼ˆä½•ã‚‚ã—ã¦ã„ãªã„çŠ¶æ…‹ï¼‰
]

# å„ãƒ•ã‚©ãƒ«ãƒ€å­˜åœ¨ãƒã‚§ãƒƒã‚¯
for cls in classes:
    path = os.path.join(DATA_DIR, cls)
    if not os.path.exists(path):
        os.makedirs(path)
        print(f"ğŸ“ {path} ã‚’æ–°è¦ä½œæˆã—ã¾ã—ãŸ")

num_classes = len(classes)
print("ã‚¯ãƒ©ã‚¹æ•°:", num_classes)
print("ã‚¯ãƒ©ã‚¹ä¸€è¦§:", classes)

# ==============================
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
# ==============================
train_ds = tf.keras.utils.image_dataset_from_directory(
    DATA_DIR,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    DATA_DIR,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE
)

# æ­£è¦åŒ–
normalization_layer = tf.keras.layers.Rescaling(1./255)
train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))

# æœ€é©åŒ–
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

# ==============================
# ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
# ==============================
data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.1),
    tf.keras.layers.RandomZoom(0.1),
])

model = tf.keras.Sequential([
    data_augmentation,
    tf.keras.layers.Conv2D(32, (3,3), activation="relu", input_shape=(64, 64, 3)),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(64, (3,3), activation="relu"),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(128, (3,3), activation="relu"),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation="relu"),
    tf.keras.layers.Dense(num_classes, activation="softmax")
])

model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

# ==============================
# å­¦ç¿’
# ==============================
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS
)

# ==============================
# ä¿å­˜
# ==============================
model.save(SAVE_PATH)
print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {SAVE_PATH}")