from asl_config import ASL_CLASSES, DATA_DIR, MODEL_DIR, EXTENTION

import tensorflow as tf
import numpy as np
import os

# ==============================
# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
# ==============================
IMAGE_SIZE = (64, 64)
BATCH_SIZE = 32
EPOCHS = 10

os.makedirs(MODEL_DIR, exist_ok=True)
MODEL_PATH = os.path.join(MODEL_DIR, f"asl_words_model.{EXTENTION}")
print(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆ: {MODEL_PATH}")

# ==============================
# ã‚¯ãƒ©ã‚¹åãƒªã‚¹ãƒˆ
# ==============================
classes = ASL_CLASSES

# å„ãƒ•ã‚©ãƒ«ãƒ€å­˜åœ¨ãƒã‚§ãƒƒã‚¯
for cls in classes:
    path = os.path.join(DATA_DIR, cls)
    if not os.path.exists(path):
        os.makedirs(path)
        print(f"ğŸ“ {path} ã‚’æ–°è¦ä½œæˆã—ã¾ã—ãŸ")

num_classes = len(classes)
print("ã‚¯ãƒ©ã‚¹æ•°:", num_classes)
print("ã‚¯ãƒ©ã‚¹ä¸€è¦§:", classes)

# ==============================
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
# ==============================
train_ds = tf.keras.utils.image_dataset_from_directory(
    DATA_DIR,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    DATA_DIR,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE
)

# æ­£è¦åŒ–
normalization_layer = tf.keras.layers.Rescaling(1./255)
train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))

# æœ€é©åŒ–
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

# ==============================
# ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
# ==============================
data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.1),
    tf.keras.layers.RandomZoom(0.1),
])

model = tf.keras.Sequential([
    data_augmentation,
    tf.keras.layers.Conv2D(32, (3,3), activation="relu", input_shape=(64, 64, 3)),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(64, (3,3), activation="relu"),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(128, (3,3), activation="relu"),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation="relu"),
    tf.keras.layers.Dense(num_classes, activation="softmax")
])

model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

# ==============================
# å­¦ç¿’
# ==============================
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS
)

# ==============================
# ä¿å­˜
# ==============================
model.save(MODEL_PATH)
print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {MODEL_PATH}")