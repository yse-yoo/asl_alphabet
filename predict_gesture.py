"""
Âãï„ÅçÊ§úÂá∫ + „Çπ„É†„Éº„Ç∏„É≥„Ç∞ + „Çπ„É©„Ç§„Éâ„Ç¶„Ç£„É≥„Éâ„Ç¶
Â≠¶ÁøíÊ∏à„Åø LSTM (T x 225) „É¢„Éá„É´„ÇíÁî®„ÅÑ„Åü„ÄÅWeb„Ç´„É°„É©„Åã„Çâ„ÅÆ„É™„Ç¢„É´„Çø„Ç§„É†ASL‰∫àÊ∏¨
"""

from asl_config import ASL_CLASSES, MODEL_DIR
from asl_config import PROB_THRESH, PRED_SMOOTH, T, LAND_DIM
from asl_config import START_MOV_THRESH, STOP_MOV_THRESH, START_FRAMES, STOP_FRAMES
import os
import cv2
import mediapipe as mp
import numpy as np
import tensorflow as tf
from collections import deque
import time

# =========================
# Ë®≠ÂÆöÔºàÂøÖË¶Å„Å´Âøú„Åò„Å¶Ë™øÊï¥Ôºâ
# =========================
MODEL_PATH = os.path.join(MODEL_DIR, f"asl_lstm_landmarks.h5")
CLASSES = ASL_CLASSES

# Âãï„ÅçÊ§úÂá∫ÔºàCÊñπÂºè„ÅÆ„Ç≠„É¢Ôºö„Éí„Çπ„ÉÜ„É™„Ç∑„Çπ„ÅßÈñãÂßã„ÉªÁµÇ‰∫Ü„ÇíÂÆâÂÆöÂåñÔºâ
# movement_score = ||vec_t - vec_(t-1)|| / sqrt(LAND_DIM)

# Ë°®Á§∫
DRAW_LANDMARKS = True       # ÁîªÈù¢„Å´„Çπ„Ç±„É´„Éà„É≥„ÇíÊèèÁîª
SHOW_FPS = True             # FPSË°®Á§∫

# =========================
# „É¢„Éá„É´Ë™≠„ÅøËæº„Åø
# =========================
model = tf.keras.models.load_model(MODEL_PATH)
print(f"‚úÖ Loaded model: {MODEL_PATH}")

# =========================
# Mediapipe ÂàùÊúüÂåñ
# =========================
mp_hands = mp.solutions.hands
mp_pose  = mp.solutions.pose
mp_draw  = mp.solutions.drawing_utils

hands = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=2,
    min_detection_confidence=0.5
)
pose = mp_pose.Pose(
    static_image_mode=False,
    min_detection_confidence=0.65
)

# =========================
# 1„Éï„É¨„Éº„É† ‚Üí (225,) „Éô„ÇØ„Éà„É´
# =========================
def extract_landmark_vec(frame_bgr: np.ndarray) -> np.ndarray:
    rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)

    pose_res  = pose.process(rgb)
    hands_res = hands.process(rgb)

    pose_list = []
    if pose_res.pose_landmarks:
        for lm in pose_res.pose_landmarks.landmark:
            pose_list.extend([lm.x, lm.y, lm.z])

    hand_list = []
    if hands_res.multi_hand_landmarks:
        for hand in hands_res.multi_hand_landmarks:
            for lm in hand.landmark:
                hand_list.extend([lm.x, lm.y, lm.z])

    arr = np.array(pose_list + hand_list, dtype=np.float32)
    if arr.size < LAND_DIM:
        arr = np.pad(arr, (0, LAND_DIM - arr.size))
    else:
        arr = arr[:LAND_DIM]
    return arr

# =========================
# „É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£ÔºàÊèèÁîªÔºâ
# =========================
def draw_overlays(frame, label, prob, state, mov, fps=None):
    h, w = frame.shape[:2]

    # Áä∂ÊÖãË°®Á§∫
    state_text = f"STATE: {state}  MOV:{mov:.4f}"
    cv2.putText(frame, state_text, (10, 28),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (180, 180, 255), 2)

    # „É©„Éô„É´Ë°®Á§∫
    if label is not None:
        txt = f"{label} ({prob:.2f})" if prob is not None else label
        cv2.putText(frame, txt, (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (60, 240, 60), 2)
    else:
        cv2.putText(frame, "...", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (160, 160, 160), 2)

    if SHOW_FPS and fps is not None:
        cv2.putText(frame, f"FPS:{fps:.1f}", (w - 150, 28),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 200, 60), 2)

# =========================
# „É°„Ç§„É≥„É´„Éº„Éó
# =========================
def main():
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("‚ùå „Ç´„É°„É©„ÅåÈñã„Åë„Åæ„Åõ„Çì")
        return
    cap.set(cv2.CAP_PROP_FRAME_WIDTH,  1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

    # „Çπ„É©„Ç§„Éâ„Ç¶„Ç£„É≥„Éâ„Ç¶ÔºàÊúÄÊñ∞T„Éï„É¨„Éº„É†Ôºâ
    landmark_buffer: deque[np.ndarray] = deque(maxlen=T)

    # ‰∫àÊ∏¨„ÅÆ„Çπ„É†„Éº„Ç∏„É≥„Ç∞
    preds_buffer: deque[np.ndarray] = deque(maxlen=PRED_SMOOTH)

    # Âãï„ÅçÊ§úÂá∫„Éí„Çπ„ÉÜ„É™„Ç∑„Çπ
    # True: Âãï‰Ωú‰∏≠ÔºàÊé®Ë´ñONÔºâ / False: ÈùôÊ≠¢ÔºàÊé®Ë´ñOFFÔºâ
    active = False
    start_cnt = 0
    stop_cnt  = 0
    prev_vec  = None

    # ÈÄüÂ∫¶Ê∏¨ÂÆö
    t_prev = time.time()
    fps = None

    print("‚úÖ Web„Ç´„É°„É©Ëµ∑ÂãïÔºàq„ÅßÁµÇ‰∫ÜÔºâ")

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # „É©„É≥„Éâ„Éû„Éº„ÇØÊäΩÂá∫
        vec = extract_landmark_vec(frame)
        landmark_buffer.append(vec)

        # Âãï„ÅçÈáèÔºàÊ≠£Ë¶èÂåñL2Ôºâ
        if prev_vec is None:
            movement = 0.0
        else:
            movement = np.linalg.norm(vec - prev_vec) / (LAND_DIM ** 0.5)
        prev_vec = vec

        # „Éí„Çπ„ÉÜ„É™„Ç∑„Çπ„ÅßÁä∂ÊÖãÈÅ∑Áßª
        if active:
            if movement < STOP_MOV_THRESH:
                stop_cnt += 1
            else:
                stop_cnt = 0
            if stop_cnt >= STOP_FRAMES:
                active = False
                preds_buffer.clear()  # Êé®Ë´ñÂ±•Ê≠¥„ÇØ„É™„Ç¢
        else:
            if movement > START_MOV_THRESH:
                start_cnt += 1
            else:
                start_cnt = 0
            if start_cnt >= START_FRAMES:
                active = True
                preds_buffer.clear()  # Êñ∞„Åó„ÅÑÂãï‰Ωú„Å∏

        # ÊèèÁîªÁî®„Çπ„Ç±„É´„Éà„É≥
        if DRAW_LANDMARKS:
            # ÂÜçÂá¶ÁêÜ„ÅØÈáç„ÅÑ„ÅÆ„ÅßÁ∞°ÊòìÊèèÁîª„Å†„Åë
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pose_res  = pose.process(rgb)
            hands_res = hands.process(rgb)
            if pose_res.pose_landmarks:
                mp_draw.draw_landmarks(frame, pose_res.pose_landmarks, mp_pose.POSE_CONNECTIONS)
            if hands_res.multi_hand_landmarks:
                for hl in hands_res.multi_hand_landmarks:
                    mp_draw.draw_landmarks(frame, hl, mp_hands.HAND_CONNECTIONS)

        # ‰∫àÊ∏¨ÔºàÊù°‰ª∂: „Éê„ÉÉ„Éï„Ç°Ê∫ÄÊùØ & Âãï‰Ωú‰∏≠Ôºâ
        label = None
        prob  = None
        if active and len(landmark_buffer) == T:
            inp = np.array(landmark_buffer, dtype=np.float32).reshape(1, T, LAND_DIM)
            pred = model.predict(inp, verbose=0)[0]  # shape: (num_classes,)
            preds_buffer.append(pred)

            # „Çπ„É†„Éº„Ç∏„É≥„Ç∞
            avg_pred = np.mean(np.stack(preds_buffer, axis=0), axis=0)
            idx = int(np.argmax(avg_pred))
            prob = float(avg_pred[idx])

            if prob >= PROB_THRESH:
                label = CLASSES[idx]
            else:
                label = "..."

        # FPS
        t_now = time.time()
        dt = t_now - t_prev
        t_prev = t_now
        if dt > 0:
            fps = 1.0 / dt

        draw_overlays(
            frame,
            label=label,
            prob=prob,
            state="ACTIVE" if active else "IDLE",
            mov=movement,
            fps=fps
        )

        cv2.imshow("ASL Realtime (C-Mode)", frame)
        key = cv2.waitKey(1)
        if key == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    print("üëã ÁµÇ‰∫Ü„Åó„Åæ„Åó„Åü")


if __name__ == "__main__":
    main()