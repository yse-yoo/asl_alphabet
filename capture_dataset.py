import cv2
import os
import mediapipe as mp
import tkinter as tk
from tkinter import ttk

# ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€
DATA_DIR = "asl_finetune_data"

# ã‚¯ãƒ©ã‚¹ä¸€è¦§ï¼ˆAã€œZ + space + nothingï¼‰
classes = [chr(i) for i in range(ord("A"), ord("Z")+1)] + ["space", "nothing"]

# å„ã‚¯ãƒ©ã‚¹ã®ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
for cls in classes:
    os.makedirs(os.path.join(DATA_DIR, cls), exist_ok=True)

# MediaPipe Hands åˆæœŸåŒ–
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=1,
    min_detection_confidence=0.7
)
mp_draw = mp.solutions.drawing_utils

# =========================
# Tkinter GUI
# =========================
root = tk.Tk()
root.title("ASL Hand Capture")

selected_class = tk.StringVar(value="A")  # åˆæœŸã‚¯ãƒ©ã‚¹

label = tk.Label(root, text="ä¿å­˜ã™ã‚‹å˜èª(ã‚¯ãƒ©ã‚¹)ã‚’é¸æŠ", font=("Arial", 14))
label.pack(pady=10)

combo = ttk.Combobox(root, values=classes, textvariable=selected_class, state="readonly", font=("Arial", 12))
combo.pack(pady=10)
combo.current(0)

status_label = tk.Label(root, text="æœªä¿å­˜", font=("Arial", 12), fg="blue")
status_label.pack(pady=10)

# ä¿å­˜ãƒ•ãƒ©ã‚°
save_flag = tk.BooleanVar(value=False)

def trigger_save():
    save_flag.set(True)
    status_label.config(text="ğŸ’¾ ä¿å­˜è¦æ±‚ã‚ã‚Š", fg="green")

save_btn = tk.Button(root, text="ä¿å­˜ (S)", command=trigger_save, font=("Arial", 12), bg="lightgreen")
save_btn.pack(pady=10)

quit_btn = tk.Button(root, text="çµ‚äº† (Q)", command=root.quit, font=("Arial", 12), bg="lightcoral")
quit_btn.pack(pady=10)

# =========================
# OpenCV ã‚«ãƒ¡ãƒ©å‡¦ç†
# =========================
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("âŒ ã‚«ãƒ¡ãƒ©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    exit()

print("âœ… ã‚«ãƒ¡ãƒ©èµ·å‹•æˆåŠŸ (GUIã§ã‚¯ãƒ©ã‚¹æŒ‡å®šå¯èƒ½)")

img_count = 0

def capture_loop():
    global img_count

    ret, frame = cap.read()
    if not ret:
        root.after(10, capture_loop)
        return

    h, w, _ = frame.shape
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = hands.process(rgb)

    bbox = None
    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            xs = [lm.x * w for lm in hand_landmarks.landmark]
            ys = [lm.y * h for lm in hand_landmarks.landmark]
            min_x, max_x = int(min(xs)) - 20, int(max(xs)) + 20
            min_y, max_y = int(min(ys)) - 20, int(max(ys)) + 20
            bbox = (min_x, min_y, max_x, max_y)
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

    # GUIã§é¸æŠä¸­ã®ã‚¯ãƒ©ã‚¹
    current_class = selected_class.get()

    # ç”»é¢ã«ã‚¯ãƒ©ã‚¹è¡¨ç¤º
    cv2.putText(frame, f"Class: {current_class} | Saved: {img_count}",
                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)

    # ä¿å­˜å‡¦ç†ï¼ˆãƒœã‚¿ãƒ³æŠ¼ã•ã‚ŒãŸã¨ãã ã‘ï¼‰
    if save_flag.get() and bbox is not None:
        min_x, min_y, max_x, max_y = bbox
        min_x, min_y = max(0, min_x), max(0, min_y)
        max_x, max_y = min(w, max_x), min(h, max_y)
        crop = frame[min_y:max_y, min_x:max_x]

        save_path = os.path.join(DATA_DIR, current_class, f"{current_class}_{img_count:03d}.jpg")
        cv2.imwrite(save_path, crop)
        print(f"ğŸ’¾ ä¿å­˜: {save_path}")
        img_count += 1
        status_label.config(text=f"ä¿å­˜ã—ã¾ã—ãŸ ({current_class})", fg="blue")
        save_flag.set(False)

    cv2.imshow("ASL Hand Capture", frame)

    # Qã‚­ãƒ¼ã§ã‚‚çµ‚äº†å¯èƒ½
    key = cv2.waitKey(1) & 0xFF
    if key == ord("q"):
        root.quit()

    root.after(10, capture_loop)

# GUI + OpenCV ä¸¦åˆ—å®Ÿè¡Œ
root.after(10, capture_loop)
root.mainloop()

cap.release()
cv2.destroyAllWindows()