from asl_config import ASL_CLASSES, DATA_DIR, MARGIN

import cv2
import os
import json
import mediapipe as mp
import tkinter as tk
from tkinter import ttk

# =========================
# è¨­å®š
# =========================
classes = ASL_CLASSES

# å„ã‚¯ãƒ©ã‚¹ç”¨ã®ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
for cls in classes:
    os.makedirs(os.path.join(DATA_DIR, cls), exist_ok=True)

# =========================
# MediaPipe åˆæœŸåŒ–
# =========================
mp_hands = mp.solutions.hands
mp_pose = mp.solutions.pose
mp_draw = mp.solutions.drawing_utils

hands = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=2,
    min_detection_confidence=0.7
)
pose = mp_pose.Pose(
    static_image_mode=False,
    model_complexity=1,
    min_detection_confidence=0.5
)

# =========================
# Tkinter GUI
# =========================
root = tk.Tk()
root.title("ASL Capture (Hands + Pose / WideBBox)")

selected_class = tk.StringVar(value=classes[0])
tk.Label(root, text="ä¿å­˜ã™ã‚‹æ‰‹è©±å˜èªã‚’é¸æŠ", font=("Arial", 14)).pack(pady=10)

combo = ttk.Combobox(root, values=classes, textvariable=selected_class, state="readonly", font=("Arial", 12))
combo.pack(pady=10)
combo.current(0)

status_label = tk.Label(root, text="æœªä¿å­˜", font=("Arial", 12), fg="blue")
status_label.pack(pady=10)

save_flag = tk.BooleanVar(value=False)
def trigger_save():
    save_flag.set(True)
    status_label.config(text="ğŸ’¾ ä¿å­˜è¦æ±‚ã‚ã‚Š", fg="green")

tk.Button(root, text="ä¿å­˜ (S)", command=trigger_save, font=("Arial", 12), bg="lightgreen").pack(pady=10)
tk.Button(root, text="çµ‚äº† (Q)", command=root.quit, font=("Arial", 12), bg="lightcoral").pack(pady=10)

# =========================
# ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–
# =========================
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

if not cap.isOpened():
    print("âŒ ã‚«ãƒ¡ãƒ©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    exit()

print("âœ… ã‚«ãƒ¡ãƒ©èµ·å‹•æˆåŠŸ (Hands + Pose / Wide Mode)")

# å„ã‚¯ãƒ©ã‚¹ã®ç”»åƒæšæ•°ã‚«ã‚¦ãƒ³ãƒˆ
img_counts = {
    cls: len([f for f in os.listdir(os.path.join(DATA_DIR, cls)) if f.lower().endswith(".jpg")])
    for cls in classes
}

# =========================
# ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ«ãƒ¼ãƒ—
# =========================
def capture_loop():
    ret, frame = cap.read()
    if not ret:
        root.after(10, capture_loop)
        return

    original = frame.copy()
    h, w, _ = frame.shape
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Hands + Pose åŒæ™‚å‡¦ç†
    hands_results = hands.process(rgb)
    pose_results = pose.process(rgb)

    # Poseæç”»
    if pose_results.pose_landmarks:
        mp_draw.draw_landmarks(frame, pose_results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

    all_hands, all_pose = [], []
    bbox = None
    all_xs, all_ys = [], []

    # Handsåº§æ¨™
    if hands_results.multi_hand_landmarks:
        for hand_landmarks in hands_results.multi_hand_landmarks:
            xs = [lm.x * w for lm in hand_landmarks.landmark]
            ys = [lm.y * h for lm in hand_landmarks.landmark]
            all_xs.extend(xs)
            all_ys.extend(ys)
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            coords = [{"x_norm": lm.x, "y_norm": lm.y, "z_norm": lm.z} for lm in hand_landmarks.landmark]
            all_hands.append(coords)

    # Poseåº§æ¨™
    if pose_results.pose_landmarks:
        for lm in pose_results.pose_landmarks.landmark:
            all_xs.append(lm.x * w)
            all_ys.append(lm.y * h)
            all_pose.append({"x_norm": lm.x, "y_norm": lm.y, "z_norm": lm.z})

    # Hands + Pose ä¸¡æ–¹ã®bboxçµ±åˆ
    if all_xs and all_ys:
        min_x, max_x = int(min(all_xs)) - MARGIN, int(max(all_xs)) + MARGIN
        min_y, max_y = int(min(all_ys)) - MARGIN, int(max(all_ys)) + MARGIN
        min_x = max(0, min_x)
        min_y = max(0, min_y)
        max_x = min(w, max_x)
        max_y = min(h, max_y)
        bbox = (min_x, min_y, max_x, max_y)
        cv2.rectangle(frame, (min_x, min_y), (max_x, max_y), (255, 0, 0), 2)

    # è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆ
    current_class = selected_class.get()
    count = img_counts[current_class]
    cv2.putText(frame, f"Class: {current_class} | Saved: {count}", (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)

    # =========================
    # ä¿å­˜å‡¦ç†
    # =========================
    if save_flag.get():
        save_flag.set(False)
        save_base = os.path.join(DATA_DIR, current_class, f"{current_class}_{count:03d}")
        plain_path = f"{save_base}.jpg"
        skel_path = f"{save_base}_skel.jpg"
        json_path = f"{save_base}.json"

        # bboxãŒã‚ã‚Œã°åˆ‡ã‚ŠæŠœãã€ãªã‘ã‚Œã°å…¨ä½“ä¿å­˜
        if bbox is not None:
            min_x, min_y, max_x, max_y = bbox
            crop_plain = original[min_y:max_y, min_x:max_x]
            crop_skel = frame[min_y:max_y, min_x:max_x]
        else:
            crop_plain = original
            crop_skel = frame

        # JSONä¿å­˜ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        data = {
            "pose": all_pose,
            "hands": all_hands
        }

        cv2.imwrite(plain_path, crop_plain)
        cv2.imwrite(skel_path, crop_skel)
        with open(json_path, "w") as f:
            json.dump(data, f, indent=2)

        img_counts[current_class] += 1
        status_label.config(text=f"ä¿å­˜ã—ã¾ã—ãŸ ({current_class})", fg="blue")
        print(f"ğŸ’¾ ä¿å­˜: {plain_path}, {skel_path}, {json_path}")

    # æ¬¡ãƒ•ãƒ¬ãƒ¼ãƒ ã¸
    cv2.imshow("ASL Capture (Hands + Pose)", frame)
    root.after(10, capture_loop)

# =========================
# ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰æ“ä½œ
# =========================
def on_key(event):
    if event.keysym.lower() == 's':
        trigger_save()
    elif event.keysym.lower() == 'q':
        root.quit()

root.bind('<Key>', on_key)
root.after(10, capture_loop)
root.mainloop()

cap.release()
cv2.destroyAllWindows()